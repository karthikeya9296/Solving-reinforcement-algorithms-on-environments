# Solving-reinforcement-algorithms-on-environments-under-uncertainty

**Objective**

The objective of the project is to implement multiple reinforcement learning and analyze their performance, accuracy, dynamic reward graphs and hyperparameters on the gymnasium environments. The project also tests real world scenarios by introducing noise such as sensor noise, turbulence, and engine failure to the environment.

The most popular algorithms for Lunar Lander and CartPole environment are Deep Q-Learning Network (DQN) or Double Deep Q-Learning Network (DDQN). However, the performance of these algorithms is tested in ideal conditions. The current project tries to imitate real world scenarios by introducing noise to also check the robustness of the algorithm and analyze their performance with other algorithms such as Advantage Actor Critic (A2C) and Asynchronous Advantage Actor Critic (A3C) and vanilla Q-Learning and Policy Gradient.


**Algorithms:**

1.	Deep Q-Learning Network (DQN)
2.	Double Deep Q-Learning Network (DDQN)
3.	Advantage Actor Critic (A2C)
4.	Asynchronous Advantage Actor Critic (A3C)

**Novel Contribution:**

The project introduces the noise in the environments to test the robustness of the implemented algorithms. The projects also cover a different algorithm to analyze their performance, accuracy, and robustness with respect to each other which have not been compared in the lunar lander and Cartpole environment. 
